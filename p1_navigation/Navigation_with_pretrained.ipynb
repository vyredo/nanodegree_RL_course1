{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['PATH'] = f\"{os.environ['PATH']}:/home/student/.local/bin\"\n",
    "# os.environ['PATH'] = f\"{os.environ['PATH']}:/opt/conda/lib/python3.10/site-packages\"\n",
    "\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/home/vidy/.local/bin\"\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/home/vidy/mambaforge/envs/py310/lib/python3.10/site-packages\"\n",
    "\n",
    "\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip freeze | grep numpy\n",
    "!pip install . > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found path: /home/vidy/RL_banana/Value-based-methods/p1_navigation/Banana_Linux/Banana.x86_64\n",
      "Mono path[0] = '/home/vidy/RL_banana/Value-based-methods/p1_navigation/Banana_Linux/Banana_Data/Managed'\n",
      "Mono config path = '/home/vidy/RL_banana/Value-based-methods/p1_navigation/Banana_Linux/Banana_Data/MonoBleedingEdge/etc'\n",
      "Preloaded 'ScreenSelector.so'\n",
      "Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "Unable to preload the following plugins:\n",
      "\tScreenSelector.so\n",
      "\tlibgrpc_csharp_ext.x86.so\n",
      "Logging to /home/vidy/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "#Load unity Banana environment\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# Path to the Unity environment binary\n",
    "env_path = \"Banana_Linux/Banana.x86_64\"\n",
    "\n",
    "# Initialize the UnityEnvironment\n",
    "env = UnityEnvironment(file_name=env_path, no_graphics=False)\n",
    "\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "state_size = len(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model from runs/Banana_Linux.pt.\n",
      "Episode 1\tScore: 14.0\n",
      "Episode 2\tScore: 20.0\n",
      "Episode 3\tScore: 17.0\n",
      "Episode 4\tScore: 17.0\n",
      "Episode 5\tScore: 17.0\n",
      "Average score over 5 episodes: 17.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dqn_dueling import DQNDueling as DQN\n",
    "import os\n",
    "\n",
    "# Hyper parameter\n",
    "device = 'cuda' \n",
    "RUNS_DIR = \"runs\"\n",
    "env_id=\"Banana_Linux\"\n",
    "os.makedirs(RUNS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "fc1_nodes = 512  \n",
    "MODEL_FILE = os.path.join(RUNS_DIR, f'{env_id}.pt')\n",
    "\n",
    "# Load the pretrained model\n",
    "checkpoint = torch.load(MODEL_FILE, map_location=device)  # Ensure compatibility with CPU/GPU\n",
    "print(f\"Loaded pretrained model from {MODEL_FILE}.\")\n",
    "policy_dqn = DQN(state_size, action_size, fc1_nodes).to(device)\n",
    "policy_dqn.load_state_dict(checkpoint['policy_model_state_dict'])\n",
    "policy_dqn.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(env, policy_dqn, n_episodes=5, max_t=1000):\n",
    "    \"\"\"Evaluate the agent in the environment.\"\"\"\n",
    "    total_score = 0  # Track cumulative score across episodes\n",
    "    for i_episode in range(1, n_episodes + 1):\n",
    "        env_info = env.reset(train_mode=False)[brain_name]  # Reset the environment\n",
    "        state = env_info.vector_observations[0]  # Get the initial state\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(device)  # Convert state to tensor\n",
    "            action_values = policy_dqn(state_tensor)  # Get action values from the policy model\n",
    "            action = torch.argmax(action_values).item()  # Select the action with the highest value\n",
    "\n",
    "            env_info = env.step(action)[brain_name]  # Take action\n",
    "            next_state = env_info.vector_observations[0]  # Get next state\n",
    "            reward = env_info.rewards[0]  # Get reward\n",
    "            done = env_info.local_done[0]  # Check if episode is done\n",
    "            score += reward\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "        total_score += score\n",
    "        print(f\"Episode {i_episode}\\tScore: {score}\")\n",
    "\n",
    "    print(f\"Average score over {n_episodes} episodes: {total_score / n_episodes}\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate(env, policy_dqn, n_episodes=5, max_t=1000)\n",
    "\n",
    "# Close the environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
